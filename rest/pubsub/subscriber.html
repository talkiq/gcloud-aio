<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>gcloud.rest.pubsub.subscriber API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>gcloud.rest.pubsub.subscriber</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals
from builtins import range
import warnings
with warnings.catch_warnings():
    warnings.simplefilter(&#34;ignore&#34;)
    from future import standard_library
standard_library.install_aliases()
from builtins import object
from gcloud.rest.auth import BUILD_GCLOUD_REST

if BUILD_GCLOUD_REST:
    pass
else:
    import aiohttp
    import asyncio
    import logging
    import time
    from typing import Awaitable
    from typing import Callable
    from typing import List
    from typing import Optional
    from typing import Tuple
    from typing import TYPE_CHECKING
    from typing import TypeVar

    from gcloud.rest.pubsub.subscriber_client import SubscriberClient
    from gcloud.rest.pubsub.subscriber_message import SubscriberMessage
    from gcloud.rest.pubsub.metrics_agent import MetricsAgent

    log = logging.getLogger(__name__)

    if TYPE_CHECKING:
        MessageQueue = asyncio.Queue[Tuple[SubscriberMessage,  # pylint: disable=unsubscriptable-object
                                           float]]
    else:
        MessageQueue = asyncio.Queue
    ApplicationHandler = Callable[[SubscriberMessage], Awaitable[None]]
    T = TypeVar(&#39;T&#39;)

    class AckDeadlineCache(object):
        def __init__(self, subscriber_client                  ,
                     subscription     , cache_timout     ):
            self.subscriber_client = subscriber_client
            self.subscription = subscription
            self.cache_timeout = cache_timout
            self.ack_deadline        = float(&#39;inf&#39;)
            self.last_refresh        = float(&#39;-inf&#39;)

        def get(self)         :
            if self.cache_outdated():
                self.refresh()
            return self.ack_deadline

        def refresh(self)        :
            try:
                sub = self.subscriber_client.get_subscription(
                    self.subscription)
                self.ack_deadline = float(sub[&#39;ackDeadlineSeconds&#39;])
            except Exception as e:
                log.warning(
                    &#39;Failed to refresh ackDeadlineSeconds value&#39;, exc_info=e)
            self.last_refresh = time.perf_counter()

        def cache_outdated(self)        :
            if (time.perf_counter() - self.last_refresh) &gt; self.cache_timeout:
                return True
            return False

    def _budgeted_queue_get(queue                    ,
                                  time_budget       )           :
        result = []
        while time_budget &gt; 0:
            start = time.perf_counter()
            try:
                message = asyncio.wait_for(
                    queue.get(), timeout=time_budget)
                result.append(message)
                queue.task_done()
            except asyncio.TimeoutError:
                break
            time_budget -= (time.perf_counter() - start)
        return result

    def acker(subscription     ,
                    ack_queue                      ,
                    subscriber_client                    ,
                    ack_window       ,
                    metrics_client              )        :
        ack_ids            = []
        while True:
            if not ack_ids:
                ack_ids.append(ack_queue.get())
                ack_queue.task_done()

            ack_ids += _budgeted_queue_get(ack_queue, ack_window)

            # acknowledge endpoint limit is 524288 bytes
            # which is ~2744 ack_ids
            if len(ack_ids) &gt; 2500:
                log.error(
                    &#39;acker is falling behind, dropping %d unacked messages&#39;,
                    len(ack_ids) - 2500)
                ack_ids = ack_ids[-2500:]
            try:
                subscriber_client.acknowledge(subscription,
                                                    ack_ids=ack_ids)
            except aiohttp.client_exceptions.ClientResponseError as e:
                if e.status == 400:
                    log.error(
                        &#39;Ack error is unrecoverable, &#39;
                        &#39;one or more messages may be dropped&#39;, exc_info=e)

                    def maybe_ack(ack_id     )        :
                        try:
                            subscriber_client.acknowledge(
                                subscription,
                                ack_ids=[ack_id])
                        except Exception as e:
                            log.warning(&#39;Ack failed for ack_id=%s&#39;,
                                        ack_id,
                                        exc_info=e)

                    for ack_id in ack_ids:
                        (maybe_ack(ack_id))
                    ack_ids = []

                log.warning(
                    &#39;Ack request failed, better luck next batch&#39;, exc_info=e)
                metrics_client.increment(&#39;pubsub.acker.batch.failed&#39;)

                continue
            except Exception as e:
                log.warning(
                    &#39;Ack request failed, better luck next batch&#39;, exc_info=e)
                metrics_client.increment(&#39;pubsub.acker.batch.failed&#39;)

                continue

            metrics_client.histogram(&#39;pubsub.acker.batch&#39;, len(ack_ids))

            ack_ids = []

    def nacker(subscription     ,
                     nack_queue                      ,
                     subscriber_client                    ,
                     nack_window       ,
                     metrics_client              )        :
        ack_ids            = []
        while True:
            if not ack_ids:
                ack_ids.append(nack_queue.get())
                nack_queue.task_done()

            ack_ids += _budgeted_queue_get(nack_queue, nack_window)

            # modifyAckDeadline endpoint limit is 524288 bytes
            # which is ~2744 ack_ids
            if len(ack_ids) &gt; 2500:
                log.error(
                    &#39;nacker is falling behind, dropping %d unacked messages&#39;,
                    len(ack_ids) - 2500)
                ack_ids = ack_ids[-2500:]
            try:
                subscriber_client.modify_ack_deadline(
                    subscription,
                    ack_ids=ack_ids,
                    ack_deadline_seconds=0)
            except asyncio.CancelledError:  # pylint: disable=try-except-raise
                raise
            except aiohttp.client_exceptions.ClientResponseError as e:
                if e.status == 400:
                    log.error(
                        &#39;Nack error is unrecoverable, &#39;
                        &#39;one or more messages may be dropped&#39;, exc_info=e)

                    def maybe_nack(ack_id     )        :
                        try:
                            subscriber_client.modify_ack_deadline(
                                subscription,
                                ack_ids=[ack_id],
                                ack_deadline_seconds=0)
                        except Exception as e:
                            log.warning(&#39;Nack failed for ack_id=%s&#39;,
                                        ack_id,
                                        exc_info=e)
                    for ack_id in ack_ids:
                        (maybe_nack(ack_id))
                    ack_ids = []

                log.warning(
                    &#39;Nack request failed, better luck next batch&#39;, exc_info=e)
                metrics_client.increment(&#39;pubsub.nacker.batch.failed&#39;)

                continue
            except Exception as e:
                log.warning(
                    &#39;Nack request failed, better luck next batch&#39;, exc_info=e)
                metrics_client.increment(&#39;pubsub.nacker.batch.failed&#39;)

                continue

            metrics_client.histogram(&#39;pubsub.nacker.batch&#39;, len(ack_ids))

            ack_ids = []

    def _execute_callback(message                   ,
                                callback                    ,
                                ack_queue                      ,
                                nack_queue                                ,
                                metrics_client              
                                )        :
        try:
            start = time.perf_counter()
            callback(message)
            ack_queue.put(message.ack_id)
            metrics_client.increment(&#39;pubsub.consumer.succeeded&#39;)
            metrics_client.histogram(&#39;pubsub.consumer.latency.runtime&#39;,
                                     time.perf_counter() - start)
        except Exception:
            if nack_queue:
                nack_queue.put(message.ack_id)
            log.exception(&#39;Application callback raised an exception&#39;)
            metrics_client.increment(&#39;pubsub.consumer.failed&#39;)

    def consumer(  # pylint: disable=too-many-locals
            message_queue              ,
            callback                    ,
            ack_queue                      ,
            ack_deadline_cache                  ,
            max_tasks     ,
            nack_queue                                ,
            metrics_client              )        :
        try:
            semaphore = asyncio.Semaphore(max_tasks)

            def _consume_one(message                   ,
                                   pulled_at       )        :
                semaphore.acquire()

                ack_deadline = ack_deadline_cache.get()
                if (time.perf_counter() - pulled_at) &gt;= ack_deadline:
                    metrics_client.increment(&#39;pubsub.consumer.failfast&#39;)
                    message_queue.task_done()
                    semaphore.release()
                    return

                metrics_client.histogram(
                    &#39;pubsub.consumer.latency.receive&#39;,
                    # publish_time is in UTC Zulu
                    # https://cloud.google.com/pubsub/docs/reference/rest/v1/PubsubMessage
                    time.time() - message.publish_time.timestamp())

                task = (_execute_callback(
                    message,
                    callback,
                    ack_queue,
                    nack_queue,
                    metrics_client,
                ))
                task.add_done_callback(lambda _f: semaphore.release())
                message_queue.task_done()

            while True:
                message, pulled_at = message_queue.get()
                asyncio.shield(_consume_one(message, pulled_at))
        except asyncio.CancelledError:
            log.info(&#39;Consumer worker cancelled. Gracefully terminating...&#39;)
            for _ in range(max_tasks):
                semaphore.acquire()

            ack_queue.join()
            if nack_queue:
                nack_queue.join()
            log.info(&#39;Consumer terminated gracefully.&#39;)
            raise

    def producer(
            subscription     ,
            message_queue              ,
            subscriber_client                    ,
            max_messages     ,
            metrics_client              )        :
        try:
            while True:
                new_messages = []
                try:
                    new_messages = subscriber_client.pull(
                        subscription=subscription,
                        max_messages=max_messages,
                        # it is important to have this value reasonably high
                        # as long lived connections may be left hanging
                        # on a server which will cause delay in message
                        # delivery or even false deadlettering if it is enabled
                        timeout=30)
                except (asyncio.TimeoutError, KeyError):
                    continue

                metrics_client.histogram(
                    &#39;pubsub.producer.batch&#39;, len(new_messages))

                pulled_at = time.perf_counter()
                while new_messages:
                    message_queue.put((new_messages[-1], pulled_at))
                    new_messages.pop()

                message_queue.join()
        except asyncio.CancelledError:
            log.info(&#39;Producer worker cancelled. Gracefully terminating...&#39;)
            pulled_at = time.perf_counter()
            for m in new_messages:
                message_queue.put((m, pulled_at))

            message_queue.join()
            log.info(&#39;Producer terminated gracefully.&#39;)
            raise

    def subscribe(subscription     ,  # pylint: disable=too-many-locals
                        handler                    ,
                        subscriber_client                  , **_3to2kwargs
                        )        :
        if &#39;metrics_client&#39; in _3to2kwargs: metrics_client = _3to2kwargs[&#39;metrics_client&#39;]; del _3to2kwargs[&#39;metrics_client&#39;]
        else: metrics_client =  None
        if &#39;nack_window&#39; in _3to2kwargs: nack_window = _3to2kwargs[&#39;nack_window&#39;]; del _3to2kwargs[&#39;nack_window&#39;]
        else: nack_window =  0.3
        if &#39;enable_nack&#39; in _3to2kwargs: enable_nack = _3to2kwargs[&#39;enable_nack&#39;]; del _3to2kwargs[&#39;enable_nack&#39;]
        else: enable_nack =  True
        if &#39;num_tasks_per_consumer&#39; in _3to2kwargs: num_tasks_per_consumer = _3to2kwargs[&#39;num_tasks_per_consumer&#39;]; del _3to2kwargs[&#39;num_tasks_per_consumer&#39;]
        else: num_tasks_per_consumer =  1
        if &#39;ack_deadline_cache_timeout&#39; in _3to2kwargs: ack_deadline_cache_timeout = _3to2kwargs[&#39;ack_deadline_cache_timeout&#39;]; del _3to2kwargs[&#39;ack_deadline_cache_timeout&#39;]
        else: ack_deadline_cache_timeout =  60
        if &#39;ack_window&#39; in _3to2kwargs: ack_window = _3to2kwargs[&#39;ack_window&#39;]; del _3to2kwargs[&#39;ack_window&#39;]
        else: ack_window =  0.3
        if &#39;max_messages_per_producer&#39; in _3to2kwargs: max_messages_per_producer = _3to2kwargs[&#39;max_messages_per_producer&#39;]; del _3to2kwargs[&#39;max_messages_per_producer&#39;]
        else: max_messages_per_producer =  100
        if &#39;num_producers&#39; in _3to2kwargs: num_producers = _3to2kwargs[&#39;num_producers&#39;]; del _3to2kwargs[&#39;num_producers&#39;]
        else: num_producers =  1
        ack_queue                       = asyncio.Queue(
            maxsize=(max_messages_per_producer * num_producers))
        nack_queue                                 = None
        ack_deadline_cache = AckDeadlineCache(subscriber_client,
                                              subscription,
                                              ack_deadline_cache_timeout)
        metrics_client = metrics_client or MetricsAgent()
        acker_tasks = []
        consumer_tasks = []
        producer_tasks = []
        try:
            acker_tasks.append((
                acker(subscription, ack_queue, subscriber_client,
                      ack_window=ack_window, metrics_client=metrics_client)
            ))
            if enable_nack:
                nack_queue = asyncio.Queue(
                    maxsize=(max_messages_per_producer * num_producers))
                acker_tasks.append((
                    nacker(subscription, nack_queue, subscriber_client,
                           nack_window=nack_window,
                           metrics_client=metrics_client)
                ))
            for _ in range(num_producers):
                q               = asyncio.Queue(
                    maxsize=max_messages_per_producer)
                consumer_tasks.append((
                    consumer(q,
                             handler,
                             ack_queue,
                             ack_deadline_cache,
                             num_tasks_per_consumer,
                             nack_queue,
                             metrics_client=metrics_client)
                ))
                producer_tasks.append((
                    producer(subscription,
                             q,
                             subscriber_client,
                             max_messages=max_messages_per_producer,
                             metrics_client=metrics_client)
                ))

            all_tasks = [*producer_tasks, *consumer_tasks, *acker_tasks]
            done, _ = asyncio.wait(all_tasks,
                                         return_when=asyncio.FIRST_COMPLETED)
            for task in done:
                task.result()
            raise Exception(&#39;A subscriber worker shut down unexpectedly!&#39;)
        except Exception as e:
            log.info(&#39;Subscriber exited&#39;, exc_info=e)
            for task in producer_tasks:
                task.cancel()
            asyncio.wait(producer_tasks,
                               return_when=asyncio.ALL_COMPLETED)

            for task in consumer_tasks:
                task.cancel()
            asyncio.wait(consumer_tasks,
                               return_when=asyncio.ALL_COMPLETED)

            for task in acker_tasks:
                task.cancel()
            asyncio.wait(acker_tasks, return_when=asyncio.ALL_COMPLETED)
        raise asyncio.CancelledError(&#39;Subscriber shut down&#39;)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="gcloud.rest.pubsub" href="index.html">gcloud.rest.pubsub</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>